%% LyX 2.2.1 created this file.  For more info, see http://www.lyx.org/.
%t% Do not edit unless you really know what you are doing.
%\documentclass[english]{article}
%\usepackage[latin9]{inputenc}

%\usepackage{babel}
%begin{document}

\documentclass[english]{article}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage[a4paper]{geometry}
\usepackage{amsmath}
\geometry{verbose,tmargin=2cm,bmargin=2cm,lmargin=2cm,rmargin=2cm}
\usepackage{graphicx}
%\usepackage[chapter]{algorithm}
\usepackage{algorithmic}
\usepackage{tabularx}
\usepackage{colortbl}
\usepackage{hhline}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}

\DeclareMathOperator*{\argmin}{\arg\!\min}
\DeclareMathOperator*{\argmax}{\arg\!\max}

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
%% Because html converters don't know tabularnewline
\providecommand{\tabularnewline}{\\}

\makeatother

\usepackage{babel}
\begin{document}

\title{Machine Learning for Computer Vision (EE5177) \\ Programming Assignment 4 : Logistic Regression and SVMs \\ Problem \#3}

\author{Akshit Kumar \\ \emph{EE14B127}}

\date{17th April 2017}

\maketitle
\tableofcontents{}

\section{Introduction}

\subsection{Goal}
The goal of this question is to compare logistic regression and SVM by classifying a dataset with 4 classes ie multiclass classification. 

\subsection{Approach}
To do Logistic Regression, we make use of the \emph{glmnet} library and use it to train and test our logistic regression model.
To do SVM classification, we make use of the \emph{libsvm} library and use it to train and test our SVM classifier.
For training the model, a lot of work in hyperparameter tuning has gone, where we divide the training set into training set and cross validation set. Find the optimal value using the minimum cross validation set error and use those parameters for testing. We make use of n-fold cross-validation for determining the best parameters.

\subsection{Result Summary}
The RBF Kernel for SVM and logistic regression perform equally well giving an accuracy of \emph{70\%} and linear Kernel for SVM performs badly and is also slow.

\section{Logistic Regression}
\subsection{Approach}
Logistic regression is performed using \emph{glmnet}.\emph{glmnet} performs a log search for the kernel parameter $\lambda$ and the model returned contains all the values of $\lambda$ used. To find the best possible value of $\lambda$ we use n-fold cross validation. We use the value n = 10 to perform n-fold cross search. To do this we use the function \emph{cvglmnet} which performs n-fold cross validation on all the values of $\lambda$ given by \emph{glmnet} to return the best value of $\lambda$.
\subsection{Result}
\begin{itemize}
	\item Accuracy = 70 \%
	\item $\lambda_{min}$ = 0.0055
 	\item $\lambda_{1se}$ = 0.0128
\end{itemize}

\section{SVM}
\subsection{Approach}
Next we perform SVM to classify the same data and obtain the accuracy. Here we use both a linear kernel as well as an RBF kernel. To obtain the kernel parameters we perform a grid
search by iterating over the following values:
\begin{itemize}
	\item C for RBF Kernel = logspace(-10,1,10)
	\item $\gamma$ for RBF Kernel = logspace(-10,1,10)
 	\item C for Linear Kernel = logspace(-10,1,10)
\end{itemize}

\subsection{Result for RBF Kernel}
\begin{itemize}
	\item Test Accuracy = 70 \%
	\item Best C = 10
 	\item Best $\gamma$ = 1.6681e-09
 	\item Best CV Accuracy = 67.1968%
\end{itemize}

\subsection{Result for Linear Kernel}
\begin{itemize}
	\item Test Accuracy = 55 \%
	\item Best C = 2.7826e-08
 	\item Best CV Accuracy = 60.0398 \%
\end{itemize}

\end{document}

